---
title: "ManyPrimates1_Data_Processing"
output:
  html_notebook:
    code_folding: hide
    css: style.css
    theme: paper
    toc: yes
    toc_float: yes
---

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(googledrive)
```

# Define helper functions

```{r}
download_file <- function(row, path) try({
  site = row$site[1]
  file <- str_c('ManyPrimates_mp1_datasheet_', site, '.xlsx')
  cat("Downloading data for", site, "\n")
  drive_download(as_id(row$id[1]), path = str_c(path, file), overwrite = TRUE, verbose = FALSE)
})

read_file <- function(site, path) try({
  file <- str_c('ManyPrimates_mp1_datasheet_', site, '.xlsx')
  cat("Reading", file, "\n")
  read_xlsx(str_c(path, file), sheet = 'Data', na = c('NA', 'n/a'), guess_max = 1500) # add to list of NA values (if necessary)
})
```
  
```{r}
check_missing <- function(name, dfs) {
  dfs[[name]] %>% 
    mutate(file = name, rows = nrow(.)) %>% 
    group_by(file, rows) %>% 
    summarise_each(list(~ ifelse(sum(is.na(.)) == 0, NA, sum(is.na(.)))))
}
```

```{r}
check_column_vals <- function(df, ref_df, col, msg_df) {
  if (all(unique(df[[col]]) %in% unique(ref_df[[col]]))) {
    msg_df = add_row(msg_df, check = str_c('check ', col), msg = '--- PASS ---')
  } else {
    msg_df = add_row(msg_df, check = str_c('check ', col), msg = '--- FAIL ---')
    msg_df = add_row(msg_df, check = '', msg = paste(unique(df[[col]]), collapse = ' '))
  }
  
  return(msg_df)
}

get_min_max_ndistinct <- function(df, col, msg_df) {
  msg = paste(min(df[[col]]), max(df[[col]]), collapse = ' ')
  msg_df = add_row(msg_df, check = str_c('check ', col), msg = msg)
  
  return(msg_df)
}
```

```{r}
check_values <- function(name, dfs) {
  df = dfs[[name]]
  msg = tibble(check = '=== FILE', msg = name)
  msg = add_row(msg, check = '=== AUTOMATIC CHECKS', msg = '')

  if (setequal(names(sample), names(df))) {
    msg = add_row(msg, check='column names', msg='--- PASS ---')
  } else {
    msg = add_row(msg, check = 'column names', msg = '--- FAIL ---')
    msg = add_row(msg, check = '-- missing columns', msg = paste(setdiff(names(sample), names(df)), collapse = ' '))
    msg = add_row(msg, check = '-- unexpected columns', msg = paste(setdiff(names(df), names(sample)), collapse = ' '))
  }

  msg = check_column_vals(df, sample, 'condition', msg)
  msg = check_column_vals(df, sample, 'task_experience', msg)
  msg = check_column_vals(df, sample, 'test_situation', msg)
  msg = check_column_vals(df, sample, 'hiding_location', msg)
  msg = check_column_vals(df, sample, 'pick', msg)
  msg = check_column_vals(df, sample, 'correct', msg)

  msg = add_row(msg, check = '=== MANUAL CHECKS', msg = '')
  
  msg = get_min_max_ndistinct(df, 'session', msg)
  msg = get_min_max_ndistinct(df, 'block', msg)
  msg = get_min_max_ndistinct(df, 'trial', msg)
  
  msg = add_row(msg, check = 'check cup distance', msg = paste(unique(df$cup_distance), collapse = ' '))
  msg = add_row(msg, check = 'check board size', msg = paste(unique(df$board_size), collapse = ' '))

  return(msg)
}
```

```{r}
check_site_specific <- function(name, dfs) {
  # writing this as a separate function because the entries can be long, which isn't easily displayed/checked in a table
  df = dfs[[name]]
  msg = c(str_c('\n=== FILE: ', name))
  msg = c(msg, '\n--check species:', paste(unique(df$species), collapse = ' '))
  msg = c(msg, '\n--check subject:', paste(unique(df$subject_site), collapse = ' '))
  msg = c(msg, '\n--check age:', paste(sort(unique(df$age)), collapse = ' '))

  return(msg)
}
```


# Load Data

```{r, message=FALSE}
# the very 1st time, run this in console
# give access to ManyPrimates Google Drive
drive_auth()
```

```{r}
# get sheet with sites and datasheet Google Drive IDs
ids = read_csv('../data/raw_data_gdrive_ids.csv') %>% arrange(site)

# download files
path = '../data/raw_data/'
for (row in 1:nrow(ids)) { download_file(ids[row,], path) }
cat('\n')

# read files into list of loaded data frames
site_names = ids$site
raw_dfs = map(site_names, read_file, path)
names(raw_dfs) = site_names
```

```{r sample, message=FALSE}
# load sample
sample = read_delim(str_c(path, "../coding_sample.csv"), delim = ",")
```

match column format

```{r}
# remove secondary pick column
for (site in c('Lincoln Park Zoo', 'UCSD')) {
  raw_dfs[[site]] <- select(raw_dfs[[site]], -secondary_pick)
}
```

```{r}
# rows with missing pick/correct
lapply(raw_dfs, filter, is.na(correct) | is.na(pick)) %>% 
  map_df(bind_rows)
```

# Check for missing values

For each file, display total number of rows (for reference) and the number of missing values for each column.  
(Only for files with missing values & only for columns in which any file has missing values. Ignore `comment` column.)

```{r}
lapply(site_names, check_missing, raw_dfs) %>% 
  map_df(bind_rows) %>% 
  select(-comment) %>% 
  filter_at(vars(-file, -rows), any_vars(!is.na(.))) %>%
  select_if(~ any(!is.na(.)))
```

# Check values I

(values that are shared across site (e.g., hiding location in [1, 2, 3]) or take on very few values within a site (e.g., cup distance))

- The automatic checks for a column test for any unexpected values. The function shows all actual unique values if the check fails.
- The manual checks for session, block, and trial list the minimum, maximum, and the number of unique values
  - If maximum trial <= 36, it _can_ mean that the trial number wasn't recorded continuously across sessions (but this can be okay, e.g., if subjects only did this many trials)

```{r, rows.print=30}
lapply(site_names, check_values, raw_dfs)
```

# Check values II

(values that can take on a lot of different values per site)

```{r}
invisible(lapply(site_names, function(f) cat(check_site_specific(f, raw_dfs), sep='\n')))
```

```{r}
# list out all comments (exact duplicates removed)
lapply(raw_dfs, function(df) filter(df, !is.na(comment)) %>% select(site, comment)) %>% 
  map_df(bind_rows) %>% 
  arrange(site, comment) %>% 
  unite('site_comment', c('site', 'comment'), sep = ': ') %>% 
  filter(!duplicated(.))
```


# vvv STILL TO BE ADAPTED

# Merge Data Frames

- remove legitimate missing values
- separate multi-word species names with underscores instead of spaces
- convert species name to lower case

```{r merge data files}
merged_data = map_df(raw_dfs, bind_rows) %>%
  mutate(species = str_replace_all(str_to_lower(species), " ", "_")) %>% 
  filter(!is.na(pick)) %>% 
  select(-comment, -date)
```

---


> - Add underscores to species names
> - Add life expectancy and normalize it
> - Make `correct` value match whether `hiding_location` and `pick` are identical

```{r add life expectancy, message=FALSE}
species_data <- read_csv("../data/species_data.csv") %>% select(species, life_expectancy)
raw_data <- raw_data %>%
  left_join(species_data, by = "species") %>%
  rename(delay = condition) %>%
  mutate(norm_age = scale(age / life_expectancy),
         correct = as.numeric(hiding_location == pick))
```

## Quality Checks

> Data structure

```{r}
glimpse(raw_data)
```

> Sample sizes

```{r, results="asis"}
raw_data %>%
  summarise(N = n_distinct(subject_site),
            n_sites = n_distinct(site) - 1, # sweetwaters and sweetwaters_group2
            n_species = n_distinct(species)) %>%
  knitr::kable()
```

```{r, results="asis"}
raw_data %>%
  group_by(site, species) %>%
  summarise(n = n_distinct(subject_site)) %>%
  knitr::kable()
```

> Are there subjects with same trial number multiple times?

```{r}
raw_data %>%
  group_by(site, species, subject_site, trial) %>%
  summarise(n = n()) %>%
  filter(n > 1)
```

> Are there any missing values?

```{r}
raw_data %>%
  select_if(function(x) any(is.na(x))) %>%
  summarise_all(funs(sum(is.na(.))))
```

> Export Merged Data

```{r write data file}
write_csv(raw_data, "../data/merged_data/01_manyprimates_pilot_merged_data_v2.csv")
```


