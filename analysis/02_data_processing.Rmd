---
title: "ManyPrimates1_Data_Processing"
output:
  html_notebook:
    code_folding: hide
    css: style.css
    theme: paper
    toc: yes
    toc_float: yes
---

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(googledrive)
```

# Define helper functions

```{r}
download_file <- function(row, path) try({
  site = row$site[1]
  file <- str_c('ManyPrimates_mp1_datasheet_', site, '.xlsx')
  cat("Downloading data for", site, "\n")
  drive_download(as_id(row$id[1]), path = str_c(path, file), overwrite = TRUE, verbose = FALSE)
})

read_file <- function(site, path) try({
  file <- str_c('ManyPrimates_mp1_datasheet_', site, '.xlsx')
  cat("Reading", file, "\n")
  read_xlsx(str_c(path, file), sheet = 'Data', na = c('NA', 'n/a'), guess_max = 1500)
})
```
  
```{r}
check_missing <- function(name, dfs) {
  dfs[[name]] %>% 
    mutate(file = name, rows = nrow(.)) %>% 
    group_by(file, rows) %>% 
    summarise_each(list(~ ifelse(sum(is.na(.)) == 0, NA, sum(is.na(.)))))
}
```

```{r}
check_column_vals <- function(df, ref_df, col, msg_df) {
  if (all(unique(df[[col]]) %in% unique(ref_df[[col]]))) {
    msg_df = add_row(msg_df, check = str_c('check ', col), msg = '--- PASS ---')
  } else {
    msg_df = add_row(msg_df, check = str_c('check ', col), msg = '--- FAIL ---')
    msg_df = add_row(msg_df, check = '', msg = paste(unique(df[[col]]), collapse = ' '))
  }
  
  return(msg_df)
}

get_min_max_ndistinct <- function(df, col, msg_df) {
  msg = paste(min(df[[col]]), max(df[[col]]), collapse = ' ')
  msg_df = add_row(msg_df, check = str_c('check ', col), msg = msg)
  
  return(msg_df)
}
```

```{r}
check_values <- function(name, dfs, sample) {
  df = dfs[[name]]
  msg = tibble(check = '=== FILE', msg = name)
  msg = add_row(msg, check = '=== AUTOMATIC CHECKS', msg = '')

  if (setequal(names(sample), names(df))) {
    msg = add_row(msg, check='column names', msg='--- PASS ---')
  } else {
    msg = add_row(msg, check = 'column names', msg = '--- FAIL ---')
    msg = add_row(msg, check = '-- missing columns', msg = paste(setdiff(names(sample), names(df)), collapse = ' '))
    msg = add_row(msg, check = '-- unexpected columns', msg = paste(setdiff(names(df), names(sample)), collapse = ' '))
  }

  msg = check_column_vals(df, sample, 'species', msg)
  msg = check_column_vals(df, sample, 'condition', msg)
  msg = check_column_vals(df, sample, 'task_experience', msg)
  msg = check_column_vals(df, sample, 'test_situation', msg)
  msg = check_column_vals(df, sample, 'hiding_location', msg)
  msg = check_column_vals(df, sample, 'pick', msg)
  msg = check_column_vals(df, sample, 'correct', msg)

  msg = add_row(msg, check = '=== MANUAL CHECKS', msg = '')
  
  msg = get_min_max_ndistinct(df, 'session', msg)
  msg = get_min_max_ndistinct(df, 'block', msg)
  msg = get_min_max_ndistinct(df, 'trial', msg)
  
  msg = add_row(msg, check = 'check cup distance', msg = paste(unique(df$cup_distance), collapse = ' '))
  msg = add_row(msg, check = 'check board size', msg = paste(unique(df$board_size), collapse = ' '))

  return(msg)
}
```

```{r}
check_site_specific <- function(name, dfs) {
  # writing this as a separate function because the entries can be long, which isn't easily displayed/checked in a table
  df = dfs[[name]]
  msg = c(str_c('\n=== FILE: ', name))
  msg = c(msg, '\n--check subject:', paste(unique(df$subject_site), collapse = ' '))
  msg = c(msg, '\n--check age:', paste(sort(unique(df$age)), collapse = ' '))

  return(msg)
}
```

```{r}
format_species <- function(species) {
  # convert to lower case
  # separate multi-word species names with underscores instead of spaces/hyphens
  # remove apostrophes
  # replace special characters
  species = str_to_lower(species)
  species = str_replace_all(species, "'", "")
  species = str_replace_all(species, " |-", "_")
  species = str_replace_all(species, "รง", "c")
  species
}
```


# Load data

```{r, message=FALSE}
# the very 1st time, run this in console
# give access to ManyPrimates Google Drive
drive_auth()
```

```{r}
path = '../data/raw_data/'

# get sheet with sites and datasheet Google Drive IDs
ids = read_csv('../data/raw_data_gdrive_ids.csv') %>% arrange(site)

# # download files
# for (row in 1:nrow(ids)) { download_file(ids[row,], path) }
# cat('\n')

# read files into list of loaded data frames
site_names = ids$site
raw_dfs = map(site_names, read_file, path)
names(raw_dfs) = site_names
```

```{r, message=FALSE}
# load sample
sample = read_delim(str_c(path, "../coding_sample.csv"), delim = ",")

# # download species spreadsheet
# drive_download(as_id('1RCLvbNWFph6bHvupetx7RDiAu5BWXK6PumgRo44ZoeM'), path = '../data/species.xlsx', overwrite = TRUE, verbose = FALSE)

# read species spreadsheet
species = read_excel('../data/species.xlsx', 'species', n_max = 45) %>% 
  rename(species = Species_English) %>% 
  select(species)

# add to sample dataframe
sample = bind_rows(sample, species)
```


# Tweaks/fixes

```{r}
# remove secondary pick column
for (site in c('Lincoln Park Zoo', 'UCSD')) {
  raw_dfs[[site]] <- select(raw_dfs[[site]], -secondary_pick)
}

# remove ambiguous choice & recode species
raw_dfs[['Strasbourg']] = raw_dfs[['Strasbourg']] %>% 
  filter(pick != '3 / 2', trial <= 36) %>% 
  mutate(pick = as.numeric(pick),
         species = recode(species, 
                          'Cebus capucinus' = 'white_faced_capuchin',
                          'Cebus apella' = 'brown_capuchin_monkey',
                          'Chlorocebus sabaeus' = 'green_monkey',
                          'Eulemur fulvus' = 'brown_lemur',
                          'Eulemur macaco' = 'black_lemur',
                          'Macaca tonkeana' = 'tonkean_macaque',
                          'Macaca fascicularis' = 'long_tailed_macaque',
                          'Macaca mulatta' = 'rhesus_macaque'
                          ))

# remove non-choice
raw_dfs[['Paris Zoo']] = raw_dfs[['Paris Zoo']] %>% 
  filter(pick != 0 & correct != 'n') %>% 
  mutate(correct = as.numeric(correct))

# recode correct = 'n' as 0
raw_dfs[['TBRI']] = raw_dfs[['TBRI']] %>% 
  mutate(
    correct = as.numeric(ifelse(correct == 'n', 0, correct)),
    species = 'olive baboon')

# renumber sessions by subject & date grouping, recode species
for (site in c('F and M', 'Strasbourg', 'Monkey Haven')) {
  raw_dfs[[site]] = raw_dfs[[site]] %>%
    group_by(subject_site) %>%
    mutate(session = cumsum(!duplicated(date)))
}

# recode species
raw_dfs[['F and M']] = raw_dfs[['F and M']] %>% 
  mutate(species = recode(species, 'capuchin' = 'brown_capuchin_monkey'))

raw_dfs[['Lagos']] = raw_dfs[['Lagos']] %>% 
  mutate(species = recode(species, 'emperaror tamarin' = 'emperor_tamarin'))

raw_dfs[['Apenheul']] = raw_dfs[['Apenheul']] %>% 
  mutate(species = recode(species, 'white-cheeked gibbon' = 'northern_white_cheeked_gibbon'))

raw_dfs[['WKPRC']] = raw_dfs[['WKPRC']] %>% 
  mutate(species = recode(species, 'gorilla' = 'western_gorilla'))

raw_dfs[['Paris Zoo']] = raw_dfs[['Paris Zoo']] %>% 
  mutate(species = recode(species, 'woolly monkey' = 'brown_woolly_monkey'))

raw_dfs[['Monkey Haven']] = raw_dfs[['Monkey Haven']] %>% 
  mutate(species = recode(species, 
                          'Langur' = 'east_javan_langur',
                          'Muller Gibbon' = 'muellers_gibbon',
                          'Lar Gibbon' = 'white_handed_gibbon'))
```

```{r}
# remove rows with missing choice/correct
# format species names
raw_dfs = raw_dfs %>% 
  lapply(filter, !is.na(correct) & !is.na(pick)) %>% 
  lapply(mutate, age = as.numeric(age)) %>% 
  lapply(mutate, species = format_species(species))
```


# Check for missing values

For each file, display total number of rows (for reference) and the number of missing values for each column.  
(Only for files with missing values & only for columns in which any file has missing values. Ignore `comment` column.)

```{r}
lapply(site_names, check_missing, raw_dfs) %>% 
  map_df(bind_rows) %>% 
  select(-comment) %>% 
  filter_at(vars(-file, -rows), any_vars(!is.na(.))) %>%
  select_if(~ any(!is.na(.)))
```


# Check values I

(values that are shared across site (e.g., hiding location in [1, 2, 3]) or take on very few values within a site (e.g., cup distance))

- The automatic checks for a column test for any unexpected values. The function shows all actual unique values if the check fails.
- The manual checks for session, block, and trial list the minimum, maximum, and the number of unique values
  - If maximum trial <= 36, it _can_ mean that the trial number wasn't recorded continuously across sessions (but this can be okay, e.g., if subjects only did this many trials)


```{r, rows.print=30}
lapply(site_names, check_values, raw_dfs, sample)
```


# Check values II

(values that can take on a lot of different values per site)

```{r}
invisible(lapply(site_names, function(f) cat(check_site_specific(f, raw_dfs), sep='\n')))
```

list out all comments (exact duplicates removed)

```{r}
lapply(raw_dfs, function(df) filter(df, !is.na(comment)) %>% ungroup %>% select(site, comment)) %>% 
  map_df(bind_rows) %>% 
  arrange(site, comment) %>% 
  unite('site_comment', c('site', 'comment'), sep = ': ') %>% 
  filter(!duplicated(.))
```

# Check whether `correct` value matches whether `hiding_location` and `pick` are identical

```{r}
map_df(raw_dfs, bind_rows) %>% 
  filter(correct != as.numeric(hiding_location == pick)) %>% 
  select(site, date, subject_site, session:correct)
```


# Check session/block/trial numbering

For below entries, the numbering may be off (e.g., not continuous or session assigned not by subject & date grouping)

```{r}
tmp = map_df(raw_dfs, bind_rows) %>% 
  group_by(site, subject_site) %>% 
  summarise(num_date = n_distinct(date), num_session = n_distinct(session), 
            min_session = min(session), max_session = max(session), 
            num_block = n_distinct(block),min_block = min(block), max_block = max(block), 
            num_trial = n(), min_trial = min(trial), max_trial = max(trial))

filter(tmp, num_date != num_session) %>% select(site:num_session)
filter(tmp, min_session + min_block + min_trial != 3) %>% select(site, subject_site, min_session, min_block, min_trial)
filter(tmp, num_session != max_session) %>% select(site, subject_site, num_session, max_session)
filter(tmp, max_trial > max_block*3) %>% select(site, subject_site, max_trial, max_block)
```

```{r}
# check that each subject has max. 3 rows of data per block
# check that each subject has trials of the same condition per block
# check that each subject has only 1 row of data for a given trial
# if not, block/trial numbering may not be continuous
map_df(raw_dfs, bind_rows) %>% 
  group_by(site, subject_site, block) %>% 
  summarise(n=n(), num_cond = n_distinct(condition)) %>% 
  filter(n > 3 | num_cond > 1)

map_df(raw_dfs, bind_rows) %>% count(site, subject_site, trial) %>% filter(n > 1)
```


# Merge data frames

remove data from sites that cannot be included

```{r, message=FALSE}
pilot_data = read_csv('../data/pilot_data/01_manyprimates_pilot_merged_data.csv')

pilot_data = pilot_data %>% 
  filter(!site %in% c('sweetwaters', 'sweetwaters_group2')) %>% 
  select(-X1, -life_expectancy, -norm_age)

raw_dfs[['Tacugama']] = NULL

raw_data = map_df(raw_dfs, bind_rows) %>%
  select(-comment, -date)

merged_data = bind_rows(pilot_data, raw_data)
```

> Data structure

```{r}
glimpse(merged_data)
```

> Sample sizes

```{r, results="asis"}
merged_data %>%
  summarise(N = n_distinct(subject_site),
            n_sites = n_distinct(site),
            n_species = n_distinct(species))
```

```{r, results="asis"}
merged_data %>%
  group_by(site, species) %>%
  summarise(n = n_distinct(subject_site))
```

> Export Merged Data

```{r write data file}
write_csv(merged_data, "../data/merged_data/ManyPrimates_mp1_merged_data.csv")
```



